{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ------- How to : build a nnUNet_translation dataset -------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 ['/home/arthurlevi10/DL-projects/nnUNet_translation/data/mr/1BA012.nii.gz', '/home/arthurlevi10/DL-projects/nnUNet_translation/data/mr/1BA014.nii.gz', '/home/arthurlevi10/DL-projects/nnUNet_translation/data/mr/1BA040.nii.gz', '/home/arthurlevi10/DL-projects/nnUNet_translation/data/mr/1BA054.nii.gz']\n",
      "4 ['/home/arthurlevi10/DL-projects/nnUNet_translation/data/ct/1BA012.nii.gz', '/home/arthurlevi10/DL-projects/nnUNet_translation/data/ct/1BA014.nii.gz', '/home/arthurlevi10/DL-projects/nnUNet_translation/data/ct/1BA040.nii.gz', '/home/arthurlevi10/DL-projects/nnUNet_translation/data/ct/1BA054.nii.gz']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import shutil, json, glob, os\n",
    "from tqdm import tqdm \n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "# Path to datasets\n",
    "data_dir = '/path_to/mr/' # contains training & validation mr.nii.gz files\n",
    "target_dir = '/path_to/ct/'  # contains training & validation ct.nii.gz files\n",
    "\n",
    "os.environ['nnUNet_results'] = '/path_to/nnUNet_translation/results/'\n",
    "os.environ['nnUNet_raw'] = '/path_to/nnUNet_translation/raw/'\n",
    "os.environ['nnUNet_preprocessed'] = '/path_to/nnUNet_translation/preprocessed/'\n",
    "\n",
    "# example with 1 input modality\n",
    "list_datas = sorted(glob.glob(os.path.join(data_dir, '*.nii.gz')))\n",
    "list_targets = sorted(glob.glob(os.path.join(target_dir, '*.nii.gz')))\n",
    "\n",
    "print(len(list_datas), list_datas)\n",
    "print(len(list_targets), list_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define dataset ID and make paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_id = 1 # /!\\ we will use both the dataset_id & the dataset_id + 1 (must be unique!)\n",
    "dataset_data_name = 'Brain_Sample_MR'    # creates Dataset001_Brain_MR\n",
    "dataset_target_name = 'Brain_Sample_CT'  # creates Dataset001_Brain_CT\n",
    "\n",
    "# we will copy the datas\n",
    "# do not use exist_ok=True, we want an error if the dataset exist already\n",
    "dataset_data_path = os.path.join(os.environ['nnUNet_raw'], f'Dataset{dataset_id:03d}_{dataset_data_name}') \n",
    "os.makedirs(dataset_data_path, exist_ok = True)\n",
    "os.makedirs(os.path.join(dataset_data_path, 'imagesTr'), exist_ok=True)\n",
    "os.makedirs(os.path.join(dataset_data_path, 'labelsTr'), exist_ok = True)\n",
    "\n",
    "dataset_target_path = os.path.join(os.environ['nnUNet_raw'], f'Dataset{dataset_id+1:03d}_{dataset_target_name}') \n",
    "os.makedirs(dataset_target_path, exist_ok = True)\n",
    "os.makedirs(os.path.join(dataset_target_path, 'imagesTr'), exist_ok = True)\n",
    "os.makedirs(os.path.join(dataset_target_path, 'labelsTr'), exist_ok = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Dataset001_Brain_MR` & `Dataset002_Brain_CT` will be located in `raw`:\n",
    "- `imagesTr` in Dataset001_Brain_MR = input\n",
    "- `imagesTr` in Dataset002_Brain_CT = target\n",
    "- both `labelsTr` contain dummy masks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Copy files and create dummy masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:02<00:00,  1.94it/s]\n",
      "100%|██████████| 4/4 [00:01<00:00,  2.13it/s]\n"
     ]
    }
   ],
   "source": [
    "def process_file(data_path, dataset_path, mat):\n",
    "    curr_nifti = nib.load(data_path)\n",
    "    filename = os.path.basename(data_path)\n",
    "    if not filename.endswith('_0000.nii.gz'):\n",
    "        filename = filename.replace('.nii.gz', '_0000.nii.gz')\n",
    "    curr_nifti.to_filename(os.path.join(dataset_path, f'imagesTr/{filename}'))\n",
    "\n",
    "    data = curr_nifti.get_fdata()\n",
    "    # Adjust the mask as needed for your specific use case. By default, the mask is set to 1 for the entire volume.\n",
    "    # This will be used for foreground preprocessing, cf https://github.com/MIC-DKFZ/nnUNet/blob/master/documentation/explanation_normalization.md\n",
    "    data = np.ones_like(data)\n",
    "\n",
    "    filename = filename.replace('_0000', '') #remove _0000 for masks\n",
    "    nib.Nifti1Image(data, mat).to_filename(os.path.join(dataset_path, f'labelsTr/{filename}'))\n",
    "\n",
    "mat = nib.load(list_datas[-1]).affine\n",
    "\n",
    "with ThreadPoolExecutor() as executor:\n",
    "    list(tqdm(executor.map(lambda data_path: process_file(data_path, dataset_data_path, mat), list_datas), total=len(list_datas)))\n",
    "\n",
    "with ThreadPoolExecutor() as executor:\n",
    "    list(tqdm(executor.map(lambda target_path: process_file(target_path, dataset_target_path, mat), list_targets), total=len(list_targets)))\n",
    "\n",
    "#### without multithreading\n",
    "# for data_path in tqdm(list_datas, total=len(list_datas)):\n",
    "#     process_file(data_path, dataset_data_path, mat)\n",
    "\n",
    "# for target_path in tqdm(list_targets, total=len(list_targets)):\n",
    "#     process_file(target_path, dataset_target_path, mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the dataset.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# /!\\ you will need to edit this with regards to the number of modalities used;\n",
    "data_dataset_json = {\n",
    "    \"labels\": {\n",
    "        \"label_001\": \"1\", \n",
    "        \"background\": 0\n",
    "    },\n",
    "    \"channel_names\": {\n",
    "        \"0\": \"MR\",\n",
    "    },\n",
    "    \"numTraining\": len(list_datas),\n",
    "    \"file_ending\": \".nii.gz\"\n",
    "}\n",
    "dump_data_datasets_path = os.path.join(dataset_data_path, 'dataset.json')\n",
    "with open(dump_data_datasets_path, 'w') as f:\n",
    "    json.dump(data_dataset_json, f)\n",
    "\n",
    "target_dataset_json = {\n",
    "    \"labels\": {\n",
    "        \"label_001\": \"1\",\n",
    "        \"background\": 0\n",
    "    },\n",
    "    \"channel_names\": {\n",
    "        \"0\": \"CT\",\n",
    "    },\n",
    "    \"numTraining\": len(list_targets),\n",
    "    \"file_ending\": \".nii.gz\"\n",
    "}\n",
    "dump_target_datasets_path = os.path.join(dataset_target_path, 'dataset.json')\n",
    "with open(dump_target_datasets_path, 'w') as f:\n",
    "    json.dump(target_dataset_json, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply preprocessing and unpacking "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- pip uninstall numpy blosc2\n",
    "- pip install numpy==1.24.3 blosc2\n",
    "- pip uninstall acvl-utils\n",
    "- pip install acvl-utils==0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fingerprint extraction...\n",
      "Dataset001_Brain_Sample_MR\n",
      "Using <class 'nnunetv2.imageio.simpleitk_reader_writer.SimpleITKIO'> as reader/writer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:06<00:00,  1.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment planning...\n",
      "Using ZScoreNormalization for image normalization\n",
      "Using ZScoreNormalization for image normalization\n",
      "Attempting to find 3d_lowres config. \n",
      "Current spacing: [1.03 1.03 1.03]. \n",
      "Current patch size: (112, 160, 128). \n",
      "Current median shape: [187.37864078 241.26213592 220.87378641]\n",
      "Using ZScoreNormalization for image normalization\n",
      "Attempting to find 3d_lowres config. \n",
      "Current spacing: [1.0609 1.0609 1.0609]. \n",
      "Current patch size: (112, 160, 128). \n",
      "Current median shape: [181.92101046 234.23508342 214.44056933]\n",
      "Dropping 3d_lowres config because the image size difference to 3d_fullres is too small. 3d_fullres: [193.  248.5 227.5], 3d_lowres: [182, 234, 214]\n",
      "Using ZScoreNormalization for image normalization\n",
      "2D U-Net configuration:\n",
      "{'data_identifier': 'nnUNetPlans_2d', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 33, 'patch_size': (256, 256), 'median_image_size_in_voxels': array([248.5, 227.5]), 'spacing': array([1., 1.]), 'normalization_schemes': ['ZScoreNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 7, 'features_per_stage': (32, 64, 128, 256, 512, 512, 512), 'conv_op': 'torch.nn.modules.conv.Conv2d', 'kernel_sizes': ((3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3)), 'strides': ((1, 1), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2)), 'n_conv_per_stage': (2, 2, 2, 2, 2, 2, 2), 'n_conv_per_stage_decoder': (2, 2, 2, 2, 2, 2), 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm2d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}, 'decoder_type': 'standard'}, '_kw_requires_import': ('conv_op', 'norm_op', 'dropout_op', 'nonlin')}, 'batch_dice': True}\n",
      "\n",
      "Using <class 'nnunetv2.imageio.simpleitk_reader_writer.SimpleITKIO'> as reader/writer\n",
      "3D fullres U-Net configuration:\n",
      "{'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': (112, 160, 128), 'median_image_size_in_voxels': array([193. , 248.5, 227.5]), 'spacing': array([1., 1., 1.]), 'normalization_schemes': ['ZScoreNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': (32, 64, 128, 256, 320, 320), 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': ((3, 3, 3), (3, 3, 3), (3, 3, 3), (3, 3, 3), (3, 3, 3), (3, 3, 3)), 'strides': ((1, 1, 1), (2, 2, 2), (2, 2, 2), (2, 2, 2), (2, 2, 2), (1, 2, 2)), 'n_conv_per_stage': (2, 2, 2, 2, 2, 2), 'n_conv_per_stage_decoder': (2, 2, 2, 2, 2), 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}, 'decoder_type': 'standard'}, '_kw_requires_import': ('conv_op', 'norm_op', 'dropout_op', 'nonlin')}, 'batch_dice': False}\n",
      "\n",
      "Plans were saved to /home/arthurlevi10/DL-projects/nnUNet_translation/preprocessed/Dataset001_Brain_Sample_MR/nnUNetPlans.json\n",
      "Preprocessing...\n",
      "Preprocessing dataset Dataset001_Brain_Sample_MR\n",
      "Configuration: 3d_fullres...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:04<00:00,  1.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n",
      "\n",
      "#######################################################################\n",
      "Please cite the following paper when using nnU-Net:\n",
      "Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.\n",
      "#######################################################################\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arthurlevi10/miniconda3/envs/nnunet_translation/lib/python3.9/site-packages/torch/amp/grad_scaler.py:132: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fingerprint extraction...\n",
      "Dataset002_Brain_Sample_CT\n",
      "Using <class 'nnunetv2.imageio.simpleitk_reader_writer.SimpleITKIO'> as reader/writer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:06<00:00,  1.72s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment planning...\n",
      "Using CTNormalization for image normalization\n",
      "Using CTNormalization for image normalization\n",
      "Attempting to find 3d_lowres config. \n",
      "Current spacing: [1.03 1.03 1.03]. \n",
      "Current patch size: (112, 160, 128). \n",
      "Current median shape: [187.37864078 241.26213592 220.87378641]\n",
      "Using CTNormalization for image normalization\n",
      "Attempting to find 3d_lowres config. \n",
      "Current spacing: [1.0609 1.0609 1.0609]. \n",
      "Current patch size: (112, 160, 128). \n",
      "Current median shape: [181.92101046 234.23508342 214.44056933]\n",
      "Dropping 3d_lowres config because the image size difference to 3d_fullres is too small. 3d_fullres: [193.  248.5 227.5], 3d_lowres: [182, 234, 214]\n",
      "Using CTNormalization for image normalization\n",
      "2D U-Net configuration:\n",
      "{'data_identifier': 'nnUNetPlans_2d', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 33, 'patch_size': (256, 256), 'median_image_size_in_voxels': array([248.5, 227.5]), 'spacing': array([1., 1.]), 'normalization_schemes': ['CTNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 7, 'features_per_stage': (32, 64, 128, 256, 512, 512, 512), 'conv_op': 'torch.nn.modules.conv.Conv2d', 'kernel_sizes': ((3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3)), 'strides': ((1, 1), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2)), 'n_conv_per_stage': (2, 2, 2, 2, 2, 2, 2), 'n_conv_per_stage_decoder': (2, 2, 2, 2, 2, 2), 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm2d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}, 'decoder_type': 'standard'}, '_kw_requires_import': ('conv_op', 'norm_op', 'dropout_op', 'nonlin')}, 'batch_dice': True}\n",
      "\n",
      "Using <class 'nnunetv2.imageio.simpleitk_reader_writer.SimpleITKIO'> as reader/writer\n",
      "3D fullres U-Net configuration:\n",
      "{'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': (112, 160, 128), 'median_image_size_in_voxels': array([193. , 248.5, 227.5]), 'spacing': array([1., 1., 1.]), 'normalization_schemes': ['CTNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': (32, 64, 128, 256, 320, 320), 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': ((3, 3, 3), (3, 3, 3), (3, 3, 3), (3, 3, 3), (3, 3, 3), (3, 3, 3)), 'strides': ((1, 1, 1), (2, 2, 2), (2, 2, 2), (2, 2, 2), (2, 2, 2), (1, 2, 2)), 'n_conv_per_stage': (2, 2, 2, 2, 2, 2), 'n_conv_per_stage_decoder': (2, 2, 2, 2, 2), 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}, 'decoder_type': 'standard'}, '_kw_requires_import': ('conv_op', 'norm_op', 'dropout_op', 'nonlin')}, 'batch_dice': False}\n",
      "\n",
      "Plans were saved to /home/arthurlevi10/DL-projects/nnUNet_translation/preprocessed/Dataset002_Brain_Sample_CT/nnUNetPlans.json\n",
      "Preprocessing...\n",
      "Preprocessing dataset Dataset002_Brain_Sample_CT\n",
      "Configuration: 3d_fullres...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:04<00:00,  1.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n",
      "\n",
      "#######################################################################\n",
      "Please cite the following paper when using nnU-Net:\n",
      "Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.\n",
      "#######################################################################\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arthurlevi10/miniconda3/envs/nnunet_translation/lib/python3.9/site-packages/torch/amp/grad_scaler.py:132: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if 'MPLBACKEND' in os.environ: \n",
    "    del os.environ['MPLBACKEND'] # avoid conflicts with matplotlib backend  \n",
    "    \n",
    "os.system(f'nnUNetv2_plan_and_preprocess -d {dataset_id} -c 3d_fullres')\n",
    "os.system(f'nnUNetv2_unpack {dataset_id} 3d_fullres 0')\n",
    "\n",
    "os.system(f'nnUNetv2_plan_and_preprocess -d {dataset_id + 1} -c 3d_fullres')\n",
    "os.system(f'nnUNetv2_unpack {dataset_id + 1} 3d_fullres 0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define 2nd modality raw data as gt_segmentations of 1st modality\n",
    "##### originally used for computing metrics / postprocessing, not sure if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/arthurlevi10/DL-projects/nnUNet_translation/preprocessed/Dataset001_Brain_Sample_MR\n",
      "/home/arthurlevi10/DL-projects/nnUNet_translation/raw/Dataset002_Brain_Sample_CT/imagesTr/1BA012_0000.nii.gz -> /home/arthurlevi10/DL-projects/nnUNet_translation/preprocessed/Dataset001_Brain_Sample_MR/gt_segmentations/1BA012.nii.gz\n",
      "/home/arthurlevi10/DL-projects/nnUNet_translation/raw/Dataset002_Brain_Sample_CT/imagesTr/1BA014_0000.nii.gz -> /home/arthurlevi10/DL-projects/nnUNet_translation/preprocessed/Dataset001_Brain_Sample_MR/gt_segmentations/1BA014.nii.gz\n",
      "/home/arthurlevi10/DL-projects/nnUNet_translation/raw/Dataset002_Brain_Sample_CT/imagesTr/1BA040_0000.nii.gz -> /home/arthurlevi10/DL-projects/nnUNet_translation/preprocessed/Dataset001_Brain_Sample_MR/gt_segmentations/1BA040.nii.gz\n",
      "/home/arthurlevi10/DL-projects/nnUNet_translation/raw/Dataset002_Brain_Sample_CT/imagesTr/1BA054_0000.nii.gz -> /home/arthurlevi10/DL-projects/nnUNet_translation/preprocessed/Dataset001_Brain_Sample_MR/gt_segmentations/1BA054.nii.gz\n"
     ]
    }
   ],
   "source": [
    "nnunet_datas_preprocessed_dir = os.path.join(os.environ['nnUNet_preprocessed'], f'Dataset{dataset_id+1:03d}_{dataset_target_name}') \n",
    "nnunet_targets_preprocessed_dir = os.path.join(os.environ['nnUNet_preprocessed'], f'Dataset{dataset_id:03d}_{dataset_data_name}') \n",
    "\n",
    "list_targets = glob.glob(os.path.join(f\"{dataset_target_path}/imagesTr\", '*'))\n",
    "list_targets.sort()\n",
    "list_gt_segmentations_datas = glob.glob(os.path.join(f\"{nnunet_targets_preprocessed_dir}/gt_segmentations\", '*'))\n",
    "list_gt_segmentations_datas.sort()\n",
    "\n",
    "print(nnunet_targets_preprocessed_dir)\n",
    "\n",
    "for (preprocessed_path, gt_path) in zip(list_targets, list_gt_segmentations_datas):\n",
    "    # here, gt_path is the path to the gt_segmentation in nnUNet_preprocessed.\n",
    "    print(preprocessed_path, \"->\", gt_path) # ensure correct file pairing; \n",
    "    shutil.copy(src = preprocessed_path, dst = gt_path) # we use shutil.copy to ensure safety, but switching to shutil.move would be more efficient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define 2nd modality preprocessed files as ground truth of 1st modality\n",
    "##### used in training, definitely needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/arthurlevi10/DL-projects/nnUNet_translation/preprocessed/Dataset002_Brain_Sample_CT/nnUNetPlans_3d_fullres/1BA012.npy -> /home/arthurlevi10/DL-projects/nnUNet_translation/preprocessed/Dataset001_Brain_Sample_MR/nnUNetPlans_3d_fullres/1BA012_seg.npy\n",
      "/home/arthurlevi10/DL-projects/nnUNet_translation/preprocessed/Dataset002_Brain_Sample_CT/nnUNetPlans_3d_fullres/1BA014.npy -> /home/arthurlevi10/DL-projects/nnUNet_translation/preprocessed/Dataset001_Brain_Sample_MR/nnUNetPlans_3d_fullres/1BA014_seg.npy\n",
      "/home/arthurlevi10/DL-projects/nnUNet_translation/preprocessed/Dataset002_Brain_Sample_CT/nnUNetPlans_3d_fullres/1BA040.npy -> /home/arthurlevi10/DL-projects/nnUNet_translation/preprocessed/Dataset001_Brain_Sample_MR/nnUNetPlans_3d_fullres/1BA040_seg.npy\n",
      "/home/arthurlevi10/DL-projects/nnUNet_translation/preprocessed/Dataset002_Brain_Sample_CT/nnUNetPlans_3d_fullres/1BA054.npy -> /home/arthurlevi10/DL-projects/nnUNet_translation/preprocessed/Dataset001_Brain_Sample_MR/nnUNetPlans_3d_fullres/1BA054_seg.npy\n"
     ]
    }
   ],
   "source": [
    "list_preprocessed_datas_seg_path = sorted(glob.glob(os.path.join(nnunet_targets_preprocessed_dir, 'nnUNetPlans_3d_fullres/*_seg.npy')))\n",
    "\n",
    "list_preprocessed_targets_path = sorted(glob.glob(os.path.join(nnunet_datas_preprocessed_dir, 'nnUNetPlans_3d_fullres/*.npy')))\n",
    "list_preprocessed_targets_path = [name for name in list_preprocessed_targets_path if '_seg' not in name]\n",
    "\n",
    "for (datas_path, targets_path) in zip(list_preprocessed_datas_seg_path, list_preprocessed_targets_path):\n",
    "    print(targets_path, \"->\", datas_path)\n",
    "    shutil.copy(src = targets_path, dst = datas_path) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### That's it!\n",
    "You should be able to start training with : \n",
    "```\n",
    "export nnUNet_raw=\"/data/alonguefosse/nnUNet/raw\"\n",
    "export nnUNet_preprocessed=\"/data/alonguefosse/nnUNet/preprocessed\"\n",
    "export nnUNet_results=\"/data/alonguefosse/nnUNet/results\"\n",
    "\n",
    "nnUNetv2_train 50 3d_fullres 0 -tr nnUNetTrainerMRCT\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nnunet_translation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
